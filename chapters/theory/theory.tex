\section{Supervised Learning}
Prediction and classification. From standard regression methods for predicting
a continuous variable, to classifying with logistic regression and neural
networks.

\subsection{Linear Regression}
\subsubsection{Ordinary Least Squares}\label{section:ols}
Suppose you have a data set consisting of $N$ data points. Each point is associated
with a scalar target $y_i$, and a vector $x$ containing values for $p$ input
features. Assuming the target variable $y_i$ is linear in the inputs, it can be
written as a linear function of the features, given by
\begin{equation}\label{eq:ols-target}
y_i = \beta_0 x_{i,0} + \beta_1 x_{i,1} + ... + \beta_{p-1} x_{i, p-1} + \varepsilon_i,
\end{equation}
where $\beta = (\beta_0, \beta_1, \dots, \beta_{p-1})^T$ is a vector of length
$p$ containing unknown values, and
$\varepsilon$ are the variables, random or otherwise, that influence the
target values, but are unaccounted for in the features $x$.
The above equation (\ref{eq:ols-target}) can be written on vector form as
\begin{equation}\label{eq:ols-target-vec}
y_i = x_i^T\beta + \varepsilon_i,
\end{equation}
and further, in matrix notation
\begin{equation}\label{eq:ols-target-mat}
\hat{y} = \vec{X}\hat{\beta} + \hat{\varepsilon}.
\end{equation}

In order to find the best possible coefficients $\beta$ we want suitable
quantity to optimize - a \textbf{cost function} $\mathcal{C}$. One example is the average
squared error, which we want to minmize.
This function is defined as
\begin{equation}
	\mathcal{C}(\beta) = \frac{1}{N}\sum\limits_{i=0}^{N-1} (y_i - f(x_i))^2
\end{equation}

This can be rewritten in matrix notation

\begin{equation}
	\mathcal{C}(\beta) = (\hat{y}-\vec{X}\beta)^T(\hat{y} - \vec{X}\beta)
\end{equation}.

As we want to minimize the residual sum of squares, we require
\begin{equation}
	\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}}
	= 0
	= \vec{X}^T(\hat{y} - \vec{X}\hat{\beta})
\end{equation}

This can be rewritten as
\begin{equation}
	\hat{X}^T\hat{y} = \hat{X}^T\hat{X}\hat{\beta}
\end{equation}.

We then assume that the matrix \(\hat{X}^T\hat{X}\)
is invertible to get the solution. ~\cite{James2000}

\subsubsection{Ridge Regression}\label{section:ridge}
OLS will not give a solution if the design matrix \(\hat{X}\) is singular
or near singular, as it depends on \(\hat{X}^T\hat{X}\) being invertible. (cite?)

Ridge regression is known as a shrinkage method. It shrinks the regression
coefficients \(\hat{\beta}\) by imposing a penalty on their size (cite?). We are in other words adding a diagonal component
to the matrix to invert. From OLS we therefore make the following change

\begin{equation}
	\hat{X}^T\hat{X} \rightarrow \hat{X}^T\hat{X} + \lambda \hat{I}
\end{equation}

where $I$ is the identity matrix. (cite?).
This gives

\begin{equation}
	RSS(\lambda) = (\hat{y}-\hat{X}\hat{\beta)}^T(\hat{y}
	- \hat{X}\hat{\beta})
	- \lambda \hat{\beta}^T\hat{\beta}
\end{equation}
and
\begin{equation}
	\hat{\beta}^{ridge} = (\hat{X}^T\hat{X}
	+ \lambda \hat{I})^{-1}\hat{X}^T\hat{y}
\end{equation}
\(\lambda > 0 \) is a complexity parameter that controls the amount
of shrinkage. The larger the value of \(\lambda\) the greater amount of
shrinkage.
\cite{James2000}

This can also be written in a non-vector format which makes
explicit the size constraint on the parameters.
It also makes it easier to see the difference from Lasso regression:

\begin{equation}
	\hat{\beta}^{ridge} = \operatorname{argmin}_{beta}
							\sum\limits_{i=1}^N \left(y_i - \beta_0
							-\sum\limits_{j=1}^p x_{ij}\beta_j\right)^2
\end{equation}
subject to
\begin{equation}
	\sum\limits_{j=1}^p \beta_j^2 \leq t
\end{equation}
There is a one to one correspondence between \(\lambda\) and \(t\).
\cite{James2000}
\subsection{Classification}
\subsubsection{Logistic Regression}\label{seq:logistic}
Differently to linear regression, classification problems
are concerned with outcomes taking the form of discrete variables.
For a specific physical problem, we'd like to identify its state, say whether
it is an ordered of disordered system. (cite?) One of the most basic examples
of a classifier algorithm is logistic regression.

\subsection{Cost Functions}\label{seq:cost-functions}
In order for a logistic regressor to improve it needs a way to
track how it's performing. This is the purpose of a cost function. Essentially,
the cost function says something about how wrong the model is in classifying the
input. The objective in machine learning, and logistic regression, is then to minimize
this error.

The cost function used in this project is called the \textbf{cross-entropy}, or the
'negative log likelihood', and takes the form
\begin{equation}\label{eq:cross-entropy}
	\mathcal{C}(\hat{\beta})=-\sum_{i=1}^n  \left(y_i(\beta_0+\beta_1x_i) -\log{(1+\exp{(\beta_0+\beta_1x_i)})}\right)
\end{equation}

\subsection{Gradient Descent}\label{seq:gradient}
Minimizing the cost function is done using Gradient Descent.
The jist of it is that in order to optimize the weights or coefficients,
and biases to minimize the cost function, one can change their values to

\begin{equation}\label{eq:delta-c}
	\frac{\partial \mathcal{C}(\hat{\beta})}{\partial \hat{\beta}} = -\hat{X}^T\left(\hat{y}-\hat{p}\right)
\end{equation}

\subsubsection{Stochastic Gradient Decent}
The stochastic gradient decent method address some of the shortcomings
of the normal gradient decent method. The gradient decent method is
for instance sensitive to the choise of learning rate (cite?).

The underlying idea of stochastic gradient decent comes form observing
that the cost function we want to minimize, almost always can be written as
a sum over \(n\) data points. (cite?). Which gives

\begin{equation}
	C(\beta) = \sum\limits_{i=1}^n c_i (\mathbf{x}_i\beta)
\end{equation} (cite?)

This means that we also can find the gradient as a sum over i gradients
as follows:

\begin{equation}
	\Delta_{\beta} C(\beta) = \sum\limits_{i}^n \Delta_{\beta}c_i (\mathbf{x}_i\beta)
\end{equation} (cite?)

Randomness is included by only taking the gradient on a subset of data.

\section{Neural Networks}
\subsection{Perceptron}

\subsubsection{Multilayer Perceptron}

\subsection{Backpropagation}

\section{Assessing the Performance of Models}
If classification accuracy is not enough to gauge whether a model is
performing well, or well in the desired way, alternative way to measure
performance must be explored. For cases of imbalanced data there are a few
widely used methods that reveal information about the model that the simple
accuracy metric can't.

\subsection{Imbalanced Data in Classification}
The physical world is rarely balanced.

A common challenge in classification is imbalanced data, in which a large
amount of the labeled data belongs to just one or a few of the classes.
For binary classification, if 90\% of the data belongs to one of the classes,
then the classifier is likely to end up placing every single
input in that class, as it will bring its accuracy to 90\%. Techincally, this
accuracy is correct, but it's not very useful since the decision isn't at all
affected by the features of the input. Accuracy alone isn't a good enough
measure of performance to reveal this.

\subsection{Confusion Matrix}
A confusion matrix is an n by n matrix containing correct classifications
on the diagonal, and false positives and negatives in the off-diagonal elements.
An example of such a matrix could be the following table:
\begin{table}[h]
    \centering
    \begin{tabular}{c|c|c|c}
     & True Cat & True Dog & True Rabbit \\
    \hline
    Predicted Cat & \textbf{5} & 2 & 0 \\
    \hline
    Predicted Dog & 3 & \textbf{3} & 2 \\
    \hline
    Predicted Rabbit & 0 & 1 & \textbf{11} \\
\end{tabular}
\caption{Confusion matrix for an example classification where the classes
         are Cat, Dog and Rabbit. Correct classifications in bold.}
\label{tab:confmat-example}
\end{table}
In the table above (\ref{tab:confmat-example}), the diagonal elements
$i = j$ are the correct classifications, while the other elements correspond
to cases where the model predicted class $i$ but should've predicted class $j$.
The confusion matrix thus gives information about false positives and false
negatives, in addition to classification accuracy. This is very useful
in cases where for example false positives can be readily ignored or filtere
later, but false negatives may have severe consequences. An example of this
could be detection of cancer, in which a false positive can be ruled out
from further testing, while a false negative may lead to a patient being sent
home when actually needing help. For a more in-depth look at confusion matrices
see \cite{Fawcett2006}.

\subsection{Receiver Operating Characteristic}
The Receiver Operating Characteristic (ROC) is a widely used measure of a
classifiers performance . The performance is measured as the effect
of the true positive rate (TPR) and the false positive rate (FPR) as a function
of thresholding the positive class. To evaluate the ROC curve for a model,
traditionally the Area Under the Curve (AUC) is used, which ranges from 0
(an ideal "opposite" classifier) to 1.0 (an ideal classifier) with 0.5
indicating a random choice classifier,
For a thorough explanation of ROC curves and the underlying concepts, see \cite{Fawcett2006}.
