Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Lathuiliere2018,
abstract = {Deep learning revolutionized data science, and recently its popularity has grown exponentially, as did the amount of papers employing deep networks. Vision tasks, such as human pose estimation, did not escape from this trend. There is a large number of deep models, where small changes in the network architecture, or in the data pre-processing, together with the stochastic nature of the optimization procedures, produce notably different results, making extremely difficult to sift methods that significantly outperform others. This situation motivates the current study, in which we perform a systematic evaluation and statistical analysis of vanilla deep regression, i.e. convolutional neural networks with a linear regression top layer. This is the first comprehensive analysis of deep regression techniques. We perform experiments on four vision problems, and report confidence intervals for the median performance as well as the statistical significance of the results, if any. Surprisingly, the variability due to different data pre-processing procedures generally eclipses the variability due to modifications in the network architecture. Our results reinforce the hypothesis according to which, in general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequately tuned can yield results close to the state-of-the-art without having to resort to more complex and ad-hoc regression models.},
archivePrefix = {arXiv},
arxivId = {1803.08450},
author = {Lathuili{\`{e}}re, St{\'{e}}phane and Mesejo, Pablo and Alameda-Pineda, Xavier and Horaud, Radu},
doi = {10.1109/TPAMI.2019.2910523},
eprint = {1803.08450},
file = {:home/ulvik/Downloads/1803.08450.pdf:pdf},
issn = {1939-3539},
pages = {1--17},
title = {{A Comprehensive Analysis of Deep Regression}},
url = {http://arxiv.org/abs/1803.08450},
year = {2018}
}
@article{Ribeiro2016,
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
archivePrefix = {arXiv},
arxivId = {arXiv:1602.04938v3},
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
doi = {10.1145/2939672.2939778},
eprint = {arXiv:1602.04938v3},
file = {:home/ulvik/Downloads/1602.04938.pdf:pdf},
isbn = {9781450342322},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135--1144},
title = {{"Why should i trust you?" Explaining the predictions of any classifier}},
volume = {13-17-August-2016},
year = {2016}
}
@article{Kuchera2019,
abstract = {We evaluate machine learning methods for event classification in the Active-Target Time Projection Chamber detector at the National Superconducting Cyclotron Laboratory (NSCL) at Michigan State University. Currently, events of interest are selected via cuts in the track fitting stage of the analysis workflow. An explicit classification step to single out the desired reaction product would result in more accurate physics results as well as a faster analysis process. We tested binary and multi-class classification methods on data produced by the 46Ar(p,p) experiment run at the NSCL in September 2015. We found that fine-tuning a pre-trained convolutional neural network produced the most successful classifier of proton scattering events in the experimental data, when trained on both experimental and simulated data. We present results from this investigation and conclude with recommendations for event classification in future experiments.},
archivePrefix = {arXiv},
arxivId = {1810.10350},
author = {Kuchera, M. P. and Ramanujan, R. and Taylor, J. Z. and Strauss, R. R. and Bazin, D. and Bradt, J. and Chen, Ruiming},
doi = {10.1016/j.nima.2019.05.097},
eprint = {1810.10350},
file = {:home/ulvik/Downloads/1810.10350.pdf:pdf},
issn = {01689002},
journal = {Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
keywords = {Active targets,Classification,Machine learning,Neural networks,Time projection chamber},
pages = {156--167},
title = {{Machine learning methods for track classification in the AT-TPC}},
volume = {940},
year = {2019}
}
